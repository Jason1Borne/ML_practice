{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "自己修改人脸识别baseline模型.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jason1Borne/ML_practice/blob/master/%E8%87%AA%E5%B7%B1%E4%BF%AE%E6%94%B9%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%ABbaseline%E6%A8%A1%E5%9E%8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbg4D16dZngD",
        "colab_type": "text"
      },
      "source": [
        "# 构建基础baseline模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA-SzW5ZZngG",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r49QbD9kZngH",
        "colab_type": "text"
      },
      "source": [
        "需要使用的工具\n",
        "- face_recognition\n",
        "- cv2\n",
        "- PIL\n",
        "- tensorflow\n",
        "- keras\n",
        "- gc \n",
        "- glob\n",
        "\n",
        "`pip install face_recognition`\n",
        "\n",
        "`pip install pillow`\n",
        "\n",
        "`pip install glob`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNlA9uhrZngJ",
        "colab_type": "text"
      },
      "source": [
        "## 一、截取人脸\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E6FaJznZngK",
        "colab_type": "text"
      },
      "source": [
        "***截取人脸***\n",
        "\n",
        "<img src=\"face_img.jpg\" style=\"zoom:20%\" >\n",
        "\n",
        "<img src=\"face_img.png\" style=\"zoom:50%\" >\n",
        "\n",
        "1. 截取人脸（注意一幅图多人脸情况）\n",
        "2. 格式转换\n",
        "3. 图片放缩（注意等比）\n",
        "4. 保存人脸"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rOXYipZZvtP",
        "colab_type": "code",
        "outputId": "3b9438b8-6834-4f28-995e-29e7b476efae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq9XquwxjS25",
        "colab_type": "code",
        "outputId": "56933be0-89dc-424d-9ebf-8b351737a038",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "!pip install face_recognition"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading https://files.pythonhosted.org/packages/3f/ed/ad9a28042f373d4633fc8b49109b623597d6f193d3bbbef7780a5ee8eef2/face_recognition-1.2.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.16.5)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (19.16.0)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K     |████████████████████████████████| 100.2MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->face_recognition) (0.46)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566176 sha256=30624ff109bcbc95df1477bfc0495358ebe4609ce7534b23ce3ae4bc6eadc1b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.2.3 face-recognition-models-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHxChyo-ZngL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import face_recognition\n",
        "import glob\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import os\n",
        "import pickle\n",
        "import gc\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "class preprocess(object):\n",
        "    def __init__(self,scale_size=139):\n",
        "        self.img_cant = []#不能被截取人脸的图片路径\n",
        "        self.scale_size = scale_size#缩放大小的比例\n",
        "\n",
        "    @staticmethod\n",
        "    def show_face(path):\n",
        "        image=face_recognition.load_image_file(path)\n",
        "        face_locations=face_recognition.face_locations(image)#一张图片可能有多张人脸所以是个list\n",
        "        if len(face_locations)==0:\n",
        "            return -1\n",
        "        for k,i in enumerate(face_locations):#i 就是生成的4个坐标可以框出一个人脸\n",
        "            (a,b,c,d)=i\n",
        "            image_spilt=image[a:c,d:b,:]\n",
        "            cv2.imshow('img_{}'.format(k),image_spilt)\n",
        "            return 1\n",
        "\n",
        "\n",
        "    def split_face(self,in_path,out_path,use_cnn):\n",
        "        image=face_recognition.load_image_file(in_path)#导入图片\n",
        "        if max(image.shape)>2000:\n",
        "            if image.shape[0]>image.shape[1]:\n",
        "                #等比放缩，避免畸变\n",
        "                image=cv2.resize(image,(2000,int(2000*image.shape[1]/image.shape[0])))\n",
        "            else:\n",
        "                image=cv2.resize(image,(int(2000*image.shape[0]/image.shape[1]),2000))\n",
        "\n",
        "        #使用cnn和不适用cnn来找人脸\n",
        "        if not use_cnn:\n",
        "            face_locations=face_recognition.face_locations(image)\n",
        "        else:\n",
        "            face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=1, model=\"cnn\")\n",
        "        #取的这张图片的地址名字作为名字\n",
        "        img_name=os.path.basename(in_path)\n",
        "        \n",
        "        #没有找到人脸就进行提示\n",
        "        if len(face_locations)==0:\n",
        "            self.img_cant.append(img_name)\n",
        "            print(img_name)\n",
        "            return\n",
        "        for k,i in enumerate(face_locations):\n",
        "            (a,b,c,d)=i\n",
        "            image_spilt=image[a:c,d:b,:]\n",
        "            #进行放缩\n",
        "            image_spilt = self.scale_img(image_spilt)\n",
        "            img=Image.fromarray(image_spilt)\n",
        "            img.save(out_path+'/{}_{}.png'.format(img_name,k))\n",
        "            print('success')\n",
        "\n",
        "    def scale_img(self,img):\n",
        "        h, w = img.shape[:2]\n",
        "        #等比放缩\n",
        "        if h > w:\n",
        "            new_h, new_w = self.scale_size * h / w, self.scale_size\n",
        "        else:\n",
        "            new_h, new_w = self.scale_size, self.scale_size * w / h\n",
        "        \n",
        "        new_h, new_w = int(new_h), int(new_w)\n",
        "        img = cv2.resize(img, (new_w, new_h))\n",
        "        \n",
        "        if new_h == new_w:\n",
        "            return img \n",
        "        elif new_h < new_w:\n",
        "            top = 0\n",
        "            left = np.random.randint(0, new_w - self.scale_size)\n",
        "            #随机截断\n",
        "        elif new_h > new_w:\n",
        "            \n",
        "            top = np.random.randint(0, new_h - self.scale_size)\n",
        "            left = 0\n",
        "            \n",
        "                \n",
        "        img = img[top: top + self.scale_size,\n",
        "                  left: left + self.scale_size]\n",
        "        return img\n",
        "\n",
        "    def preprocess(self,in_path,out_path,use_cnn=False):\n",
        "        path_lst=glob.glob(in_path+'/*.jpg')\n",
        "        for index,path in enumerate(path_lst):\n",
        "            if index % 20==0:\n",
        "                gc.collect()\n",
        "                #每隔20清一次\n",
        "            print(path)\n",
        "            self.split_face(path,out_path,use_cnn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfbpkTmCZngP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir_lst = ['/content/drive/My Drive/Colab Notebooks/表情识别/{}'.format(i) for i in range(5)]\n",
        "train_ins = preprocess()\n",
        "for in_path in dir_lst:\n",
        "    out_path = '/content/drive/My Drive/Colab Notebooks/表情识别/'+ os.path.basename(in_path)+'_face'\n",
        "    if not os.path.exists(out_path):\n",
        "        os.mkdir(out_path)\n",
        "    train_ins.preprocess(in_path,out_path,use_cnn=False)\n",
        "    with open('train_face_cant_{}.pkl'.format(os.path.basename(in_path)),'wb') as f:\n",
        "        pickle.dump(train_ins.img_cant,f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HovVs1BnZngj",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# 二、生成tfrecord"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxWuyRMJZngk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#图像标签生成tfrecord函数\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import sys\n",
        "def image2tfrecord(image_list,label_list,filename):\n",
        "    '''\n",
        "    image_list:image path list\n",
        "    label_list:label list\n",
        "    '''\n",
        "    length=len(image_list)\n",
        "    writer=tf.python_io.TFRecordWriter(filename)\n",
        "    for i in range(length):\n",
        "        if i % 100==0:\n",
        "            ratio=round(i/float(length),4)\n",
        "            sys.stdout.write('ratio:{}\\r'.format(ratio))\n",
        "            sys.stdout.flush()\n",
        "        image=Image.open(image_list[i])\n",
        "        if 'png' in image_list[i][-4:]:\n",
        "            if image.mode=='RGB':\n",
        "                r, g, b = image.split()\n",
        "                image = Image.merge(\"RGB\", (r, g, b))\n",
        "            elif image.mode=='L':\n",
        "                pass\n",
        "            else:\n",
        "                r,g, b, a = image.split()\n",
        "                image = Image.merge(\"RGB\", (r, g, b))\n",
        "        image=image.resize((139,139))\n",
        "        #这个地方就展开了\n",
        "        image_bytes=image.tobytes()\n",
        "        features={}\n",
        "        features['image']=tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_bytes]))\n",
        "        features['label']=tf.train.Feature(int64_list=tf.train.Int64List(value=[int(label_list[i])]))\n",
        "        tf_features=tf.train.Features(feature=features)\n",
        "        tf_example=tf.train.Example(features=tf_features)\n",
        "        tf_serialized=tf_example.SerializeToString()\n",
        "        writer.write(tf_serialized)\n",
        "    writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zyeygzsZngp",
        "colab_type": "code",
        "outputId": "1b69a55c-6098-4654-b968-6ab9ba2c4290",
        "colab": {}
      },
      "source": [
        "cwd = os.path.join(os.getcwd(),'face')\n",
        "# 生成10个tfrecords\n",
        "# 划分了训练集和验证集\n",
        "random_ratio = 0.05\n",
        "sum_number = 0\n",
        "for i in range(5):\n",
        "    print(i)\n",
        "    image_list = np.array(glob.glob(os.path.join(cwd,'{}_face'.format(i))+'/*.png'))\n",
        "    test_choice = np.random.choice(range(len(image_list)),size=int(len(image_list)*random_ratio))\n",
        "    train_choice = list(set(range(len(image_list))).difference(test_choice))\n",
        "    image_list_train = image_list[train_choice]\n",
        "    image_list_test = image_list[test_choice]\n",
        "    label_list = np.zeros(len(image_list))+i\n",
        "    image2tfrecord(image_list_train,np.zeros(len(image_list_train))+i,'face_train_{}.tfrecords'.format(i))\n",
        "    image2tfrecord(image_list_test,np.zeros(len(image_list_test))+i,'face_test_{}.tfrecords'.format(i))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1atio:0.0119\n",
            "2atio:0.9333\n",
            "3atio:0.9479\n",
            "4atio:0.0485\n",
            "ratio:0.0643\r"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4nrnnJ2Zngs",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# 三、使用生成器准备数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeIWDjf2Zngt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#解析函数\n",
        "def pares_tf(example_proto):\n",
        "    dics={}\n",
        "    dics['label']=tf.FixedLenFeature((),dtype=tf.int64,default_value=0)\n",
        "    dics['image']=tf.FixedLenFeature((),dtype=tf.string,default_value=\"\")\n",
        "\n",
        "    parsed_example=tf.parse_single_example(serialized=example_proto,features=dics)\n",
        "    image=tf.decode_raw(parsed_example['image'],out_type=tf.uint8)\n",
        "    #image=tf.image.decode_jpeg(parsed_example['image'], channels=1)\n",
        "    #这个地方可以加一些操作\n",
        "    image=tf.reshape(image,(139,139,3))\n",
        "    \n",
        "    #image = tf.image.rgb_to_grayscale(image)\n",
        "    image=pre_process(image)\n",
        "    \n",
        "    image=tf.cast(image,tf.float32)/255\n",
        "    #标签的操作\n",
        "    label=parsed_example['label']\n",
        "    label=tf.cast(label,tf.int32)\n",
        "    label = tf.one_hot(label,depth=5,on_value=1.0,off_value=0.0)\n",
        "    return image,label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qca2a8MyZngw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dataset\n",
        "def dataset(filenames,batch_size,epochs):\n",
        "    dataset=tf.data.TFRecordDataset(filenames=filenames)\n",
        "    new_dataset=dataset.map(pares_tf)\n",
        "    \n",
        "    return new_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvz007K2Zngz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 图像预处理\n",
        "def pre_process(images,random_flip_up_down=False,random_flip_left_right=False,random_brightness=True,random_contrast=True,random_saturation=False,random_hue=False):\n",
        "    if random_flip_up_down:\n",
        "        images = tf.image.random_flip_up_down(images)\n",
        "    if random_flip_left_right:\n",
        "        images = tf.image.random_flip_left_right(images)\n",
        "    if random_brightness:\n",
        "        images = tf.image.random_brightness(images, max_delta=0.2)\n",
        "    if random_contrast:\n",
        "        images = tf.image.random_contrast(images, 0.9, 1.1)\n",
        "    if random_saturation:\n",
        "        images = tf.image.random_saturation(images, 0.3, 0.5)\n",
        "    if random_hue:\n",
        "        images = tf.image.random_hue(images,0.2)\n",
        "#     new_size = tf.constant([160,160],dtype=tf.int32)\n",
        "#     images = tf.image.resize_images(images, new_size)\n",
        "    return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k34ZWGKnZng2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "filenames=['/content/drive/My Drive/Colab Notebooks/表情识别/face_train_{}.tfrecords'.format(i) for i in range(5)]\n",
        "next_element=dataset(filenames,batch_size=5,epochs=1)\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqBS19tcZng6",
        "colab_type": "code",
        "outputId": "f0ae37c6-39bd-4bd5-9ee8-c6819dcfef2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    batch_images,batch_labels=sess.run([next_element[0],next_element[1]])\n",
        "    for i in range(batch_images.shape[0]):\n",
        "        print(batch_images[i].shape)\n",
        "        img = np.array(batch_images[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-ae3899382f81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mbatch_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'DatasetV1Adapter' object does not support indexing"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMDJhLmGZng9",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# 四、构建模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0Zq7gOF1TGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import sys\n",
        "import glob\n",
        "from tensorflow.keras.models import Sequential, Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LQc962slewL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOoXZys6hHRk",
        "colab_type": "code",
        "outputId": "d74b0703-67dd-43d6-ac13-f66124c5f689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "\n",
        "input_data = tf.keras.Input(shape=(139,139,3))\n",
        "\n",
        "inception_model = VGG19(include_top=False, weights='imagenet', input_tensor=input_data, input_shape=(139, 139, 3))\n",
        "\n",
        "inception_model.trainable = False\n",
        "\n",
        "# inception_model.layers[1].trainable = True\n",
        "\n",
        "# inception_model.layers[4].trainable = True\n",
        "\n",
        "output = inception_model.output\n",
        "\n",
        "output = tf.keras.layers.Conv2D(512, (3,3), padding='same', strides=1, activation='relu')(output)\n",
        "\n",
        "\n",
        "output = tf.keras.layers.Conv2D(1024, (2,2), padding='same', strides=1, activation='relu')(output)\n",
        "\n",
        "output = tf.keras.layers.Flatten()(output)\n",
        "\n",
        "output = tf.keras.layers.Dense(128, activation='relu')(output)\n",
        "\n",
        "output = tf.keras.layers.Dense(64, activation='relu')(output)\n",
        "\n",
        "output = tf.keras.layers.Dropout(0.5)(output)\n",
        "\n",
        "output = tf.keras.layers.Dense(5, activation='softmax')(output)\n",
        "\n",
        "model = Model(input_data, output)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEm9FiKKkhFI",
        "colab_type": "code",
        "outputId": "6b22fb5e-22b9-4d14-d202-4e101f77bb30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 139, 139, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 139, 139, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 139, 139, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 69, 69, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 69, 69, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 69, 69, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 34, 34, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 34, 34, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 34, 34, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 34, 34, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 34, 34, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 17, 17, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 17, 17, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 17, 17, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 17, 17, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 17, 17, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 4, 4, 1024)        2098176   \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               2097280   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 26,588,229\n",
            "Trainable params: 6,563,845\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7usfqQ_Zng-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input_data = tf.placeholder(tf.float32,shape=(None,139,139,3))\n",
        "# input_label = tf.placeholder(tf.float32,shape=(None,5))\n",
        "input_data = tf.keras.Input(shape=(139,139,1))\n",
        "#139\n",
        "hidden = tf.keras.layers.Conv2D(filters=16,kernel_size=3,strides=1,padding='valid',activation='relu')(input_data)\n",
        "#137\n",
        "hidden = tf.keras.layers.MaxPool2D(pool_size=2)(hidden)\n",
        "#68\n",
        "hidden = tf.keras.layers.Conv2D(filters=32,kernel_size=3,strides=2,padding='same',activation='relu')(hidden)\n",
        "#34\n",
        "hidden = tf.keras.layers.MaxPool2D(pool_size=2)(hidden)\n",
        "#17\n",
        "hidden = tf.keras.layers.Conv2D(filters=64,kernel_size=3,strides=2,padding='valid',activation='relu')(hidden)\n",
        "#8\n",
        "hidden = tf.keras.layers.MaxPool2D(pool_size=2)(hidden)\n",
        "#4\n",
        "hidden = tf.keras.layers.Conv2D(filters=128,kernel_size=3,strides=2,padding='valid',activation='relu')(hidden)\n",
        "#1\n",
        "hidden = tf.keras.layers.Flatten()(hidden)\n",
        "\n",
        "hidden = tf.keras.layers.Dense(32, activation='relu')(hidden)\n",
        "\n",
        "output = tf.keras.layers.Dense(5,activation='softmax')(hidden)\n",
        "\n",
        "model = Model(input_data, output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBO0L_n3Soxj",
        "colab_type": "code",
        "outputId": "880cca2c-8851-42f4-9b8c-460c6ab2ed35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/Colab Notebooks/facenet_keras.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn4iLArKWVlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('/content/drive/My Drive/Colab Notebooks/facenet_keras_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5CiuOD3X92W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP28bPXhXCyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_data = tf.keras.Input(shape=(160,160,3))\n",
        "\n",
        "hidden = model(input_data)\n",
        "\n",
        "\n",
        "output = tf.keras.layers.Dense(128,activation='relu')(hidden)\n",
        "\n",
        "output = tf.keras.layers.Dense(64,activation='relu')(hidden)\n",
        "\n",
        "output = tf.keras.layers.Dense(32,activation='relu')(hidden)\n",
        "\n",
        "output = tf.keras.layers.Dense(5,activation='softmax')(hidden)\n",
        "\n",
        "model = Model(input_data, output)\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVg-mHtW-ThH",
        "colab_type": "code",
        "outputId": "8d3026b4-c1f8-4649-dc66-31b96d2b5427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_resnet_v1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_1a_3x3 (Conv2D)          (None, 79, 79, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_1a_3x3_BatchNorm (BatchN (None, 79, 79, 32)   96          Conv2d_1a_3x3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_1a_3x3_Activation (Activ (None, 79, 79, 32)   0           Conv2d_1a_3x3_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2a_3x3 (Conv2D)          (None, 77, 77, 32)   9216        Conv2d_1a_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2a_3x3_BatchNorm (BatchN (None, 77, 77, 32)   96          Conv2d_2a_3x3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2a_3x3_Activation (Activ (None, 77, 77, 32)   0           Conv2d_2a_3x3_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2b_3x3 (Conv2D)          (None, 77, 77, 64)   18432       Conv2d_2a_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2b_3x3_BatchNorm (BatchN (None, 77, 77, 64)   192         Conv2d_2b_3x3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2b_3x3_Activation (Activ (None, 77, 77, 64)   0           Conv2d_2b_3x3_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "MaxPool_3a_3x3 (MaxPooling2D)   (None, 38, 38, 64)   0           Conv2d_2b_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_3b_1x1 (Conv2D)          (None, 38, 38, 80)   5120        MaxPool_3a_3x3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_3b_1x1_BatchNorm (BatchN (None, 38, 38, 80)   240         Conv2d_3b_1x1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_3b_1x1_Activation (Activ (None, 38, 38, 80)   0           Conv2d_3b_1x1_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4a_3x3 (Conv2D)          (None, 36, 36, 192)  138240      Conv2d_3b_1x1_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4a_3x3_BatchNorm (BatchN (None, 36, 36, 192)  576         Conv2d_4a_3x3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4a_3x3_Activation (Activ (None, 36, 36, 192)  0           Conv2d_4a_3x3_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4b_3x3 (Conv2D)          (None, 17, 17, 256)  442368      Conv2d_4a_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4b_3x3_BatchNorm (BatchN (None, 17, 17, 256)  768         Conv2d_4b_3x3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4b_3x3_Activation (Activ (None, 17, 17, 256)  0           Conv2d_4b_3x3_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_1_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_1_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_1_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_1_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_1_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_1_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_1_Branch_1_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0c_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_1_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_1_Branch_1_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_1_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block35_1_Branch_1_Conv2d_0b_3x3_\n",
            "                                                                 Block35_1_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_1_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Conv2d_4b_3x3_Activation[0][0]   \n",
            "                                                                 Block35_1_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Activation (Activatio (None, 17, 17, 256)  0           Block35_1_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_2_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_2_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_2_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_2_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_2_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_2_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_2_Branch_1_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0c_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_2_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_2_Branch_1_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_2_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block35_2_Branch_1_Conv2d_0b_3x3_\n",
            "                                                                 Block35_2_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_2_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_1_Activation[0][0]       \n",
            "                                                                 Block35_2_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Activation (Activatio (None, 17, 17, 256)  0           Block35_2_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_3_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_3_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_3_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_3_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_3_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_3_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_3_Branch_1_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0c_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_3_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_3_Branch_1_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_3_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block35_3_Branch_1_Conv2d_0b_3x3_\n",
            "                                                                 Block35_3_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_3_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_2_Activation[0][0]       \n",
            "                                                                 Block35_3_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Activation (Activatio (None, 17, 17, 256)  0           Block35_3_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_4_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_4_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_4_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_4_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_4_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_4_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_4_Branch_1_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0c_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_4_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_4_Branch_1_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_4_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block35_4_Branch_1_Conv2d_0b_3x3_\n",
            "                                                                 Block35_4_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_4_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_3_Activation[0][0]       \n",
            "                                                                 Block35_4_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Activation (Activatio (None, 17, 17, 256)  0           Block35_4_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_5_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_5_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_5_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_5_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_5_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_5_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_5_Branch_1_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0c_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_5_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_5_Branch_1_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_5_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block35_5_Branch_1_Conv2d_0b_3x3_\n",
            "                                                                 Block35_5_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_5_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_4_Activation[0][0]       \n",
            "                                                                 Block35_5_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Activation (Activatio (None, 17, 17, 256)  0           Block35_5_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  49152       Block35_5_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  576         Mixed_6a_Branch_1_Conv2d_0a_1x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  0           Mixed_6a_Branch_1_Conv2d_0a_1x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  331776      Mixed_6a_Branch_1_Conv2d_0a_1x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  576         Mixed_6a_Branch_1_Conv2d_0b_3x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  0           Mixed_6a_Branch_1_Conv2d_0b_3x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    884736      Block35_5_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    442368      Mixed_6a_Branch_1_Conv2d_0b_3x3_A\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    1152        Mixed_6a_Branch_0_Conv2d_1a_3x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    768         Mixed_6a_Branch_1_Conv2d_1a_3x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    0           Mixed_6a_Branch_0_Conv2d_1a_3x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    0           Mixed_6a_Branch_1_Conv2d_1a_3x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_2_MaxPool_1a_3x (None, 8, 8, 256)    0           Block35_5_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a (Concatenate)          (None, 8, 8, 896)    0           Mixed_6a_Branch_0_Conv2d_1a_3x3_A\n",
            "                                                                 Mixed_6a_Branch_1_Conv2d_1a_3x3_A\n",
            "                                                                 Mixed_6a_Branch_2_MaxPool_1a_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_1_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0b_1x7[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_1_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_1_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0c_7x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_1_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_1_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block17_1_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_1_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Mixed_6a[0][0]                   \n",
            "                                                                 Block17_1_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Activation (Activatio (None, 8, 8, 896)    0           Block17_1_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_1_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_2_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0b_1x7[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_1_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_2_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_2_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0c_7x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_2_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_2_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block17_2_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_2_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_1_Activation[0][0]       \n",
            "                                                                 Block17_2_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Activation (Activatio (None, 8, 8, 896)    0           Block17_2_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_2_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_3_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0b_1x7[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_2_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_3_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_3_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0c_7x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_3_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_3_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block17_3_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_3_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_2_Activation[0][0]       \n",
            "                                                                 Block17_3_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Activation (Activatio (None, 8, 8, 896)    0           Block17_3_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_3_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_4_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0b_1x7[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_3_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_4_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_4_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0c_7x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_4_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_4_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block17_4_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_4_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_3_Activation[0][0]       \n",
            "                                                                 Block17_4_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Activation (Activatio (None, 8, 8, 896)    0           Block17_4_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_4_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_5_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0b_1x7[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_4_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_5_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_5_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0c_7x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_5_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_5_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block17_5_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_5_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_4_Activation[0][0]       \n",
            "                                                                 Block17_5_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Activation (Activatio (None, 8, 8, 896)    0           Block17_5_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_5_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_6_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0b_1x7[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_5_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_6_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_6_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0c_7x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_6_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_6_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block17_6_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_6_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_5_Activation[0][0]       \n",
            "                                                                 Block17_6_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Activation (Activatio (None, 8, 8, 896)    0           Block17_6_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_6_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_7_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0b_1x7[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_6_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_7_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_7_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0c_7x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_7_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_7_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block17_7_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_7_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_6_Activation[0][0]       \n",
            "                                                                 Block17_7_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Activation (Activatio (None, 8, 8, 896)    0           Block17_7_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_7_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_8_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0b_1x7[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_7_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_8_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_8_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0c_7x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_8_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_8_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block17_8_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_8_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_7_Activation[0][0]       \n",
            "                                                                 Block17_8_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Activation (Activatio (None, 8, 8, 896)    0           Block17_8_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_8_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_9_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0b_1x7[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_8_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_9_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_9_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0c_7x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_9_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_9_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block17_9_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_9_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_8_Activation[0][0]       \n",
            "                                                                 Block17_9_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Activation (Activatio (None, 8, 8, 896)    0           Block17_9_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    114688      Block17_9_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0a_1x1\n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0a_1x1\n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    114688      Block17_10_Branch_1_Conv2d_0a_1x1\n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0b_1x7\n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0b_1x7\n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_0_Conv2d_1x1  (None, 8, 8, 128)    114688      Block17_9_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    114688      Block17_10_Branch_1_Conv2d_0b_1x7\n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_0_Conv2d_1x1_ (None, 8, 8, 128)    384         Block17_10_Branch_0_Conv2d_1x1[0]\n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0c_7x1\n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_0_Conv2d_1x1_ (None, 8, 8, 128)    0           Block17_10_Branch_0_Conv2d_1x1_Ba\n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0c_7x1\n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Concatenate (Concate (None, 8, 8, 256)    0           Block17_10_Branch_0_Conv2d_1x1_Ac\n",
            "                                                                 Block17_10_Branch_1_Conv2d_0c_7x1\n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Conv2d_1x1 (Conv2D)  (None, 8, 8, 896)    230272      Block17_10_Concatenate[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_ScaleSum (Lambda)    (None, 8, 8, 896)    0           Block17_9_Activation[0][0]       \n",
            "                                                                 Block17_10_Conv2d_1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Activation (Activati (None, 8, 8, 896)    0           Block17_10_ScaleSum[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_2_Conv2d_0a_1x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_2_Conv2d_0a_1x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    589824      Mixed_7a_Branch_2_Conv2d_0a_1x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_0_Conv2d_0a_1x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_1_Conv2d_0a_1x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    768         Mixed_7a_Branch_2_Conv2d_0b_3x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_0_Conv2d_0a_1x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_1_Conv2d_0a_1x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    0           Mixed_7a_Branch_2_Conv2d_0b_3x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    884736      Mixed_7a_Branch_0_Conv2d_0a_1x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    589824      Mixed_7a_Branch_1_Conv2d_0a_1x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    589824      Mixed_7a_Branch_2_Conv2d_0b_3x3_A\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    1152        Mixed_7a_Branch_0_Conv2d_1a_3x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    768         Mixed_7a_Branch_1_Conv2d_1a_3x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    768         Mixed_7a_Branch_2_Conv2d_1a_3x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    0           Mixed_7a_Branch_0_Conv2d_1a_3x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    0           Mixed_7a_Branch_1_Conv2d_1a_3x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    0           Mixed_7a_Branch_2_Conv2d_1a_3x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_3_MaxPool_1a_3x (None, 3, 3, 896)    0           Block17_10_Activation[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a (Concatenate)          (None, 3, 3, 1792)   0           Mixed_7a_Branch_0_Conv2d_1a_3x3_A\n",
            "                                                                 Mixed_7a_Branch_1_Conv2d_1a_3x3_A\n",
            "                                                                 Mixed_7a_Branch_2_Conv2d_1a_3x3_A\n",
            "                                                                 Mixed_7a_Branch_3_MaxPool_1a_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Mixed_7a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0a_1x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0a_1x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_1_Branch_1_Conv2d_0a_1x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0b_1x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0b_1x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Mixed_7a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_1_Branch_1_Conv2d_0b_1x3_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_1_Branch_0_Conv2d_1x1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0c_3x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_1_Branch_0_Conv2d_1x1_Batc\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0c_3x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_1_Branch_0_Conv2d_1x1_Acti\n",
            "                                                                 Block8_1_Branch_1_Conv2d_0c_3x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_1_Concatenate[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Mixed_7a[0][0]                   \n",
            "                                                                 Block8_1_Conv2d_1x1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Activation (Activation (None, 3, 3, 1792)   0           Block8_1_ScaleSum[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_1_Activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0a_1x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0a_1x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_2_Branch_1_Conv2d_0a_1x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0b_1x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0b_1x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_1_Activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_2_Branch_1_Conv2d_0b_1x3_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_2_Branch_0_Conv2d_1x1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0c_3x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_2_Branch_0_Conv2d_1x1_Batc\n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0c_3x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_2_Branch_0_Conv2d_1x1_Acti\n",
            "                                                                 Block8_2_Branch_1_Conv2d_0c_3x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_2_Concatenate[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_1_Activation[0][0]        \n",
            "                                                                 Block8_2_Conv2d_1x1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Activation (Activation (None, 3, 3, 1792)   0           Block8_2_ScaleSum[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_2_Activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0a_1x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0a_1x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_3_Branch_1_Conv2d_0a_1x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0b_1x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0b_1x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_2_Activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_3_Branch_1_Conv2d_0b_1x3_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_3_Branch_0_Conv2d_1x1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0c_3x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_3_Branch_0_Conv2d_1x1_Batc\n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0c_3x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_3_Branch_0_Conv2d_1x1_Acti\n",
            "                                                                 Block8_3_Branch_1_Conv2d_0c_3x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_3_Concatenate[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_2_Activation[0][0]        \n",
            "                                                                 Block8_3_Conv2d_1x1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Activation (Activation (None, 3, 3, 1792)   0           Block8_3_ScaleSum[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_3_Activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0a_1x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0a_1x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_4_Branch_1_Conv2d_0a_1x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0b_1x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0b_1x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_3_Activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_4_Branch_1_Conv2d_0b_1x3_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_4_Branch_0_Conv2d_1x1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0c_3x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_4_Branch_0_Conv2d_1x1_Batc\n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0c_3x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_4_Branch_0_Conv2d_1x1_Acti\n",
            "                                                                 Block8_4_Branch_1_Conv2d_0c_3x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_4_Concatenate[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_3_Activation[0][0]        \n",
            "                                                                 Block8_4_Conv2d_1x1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Activation (Activation (None, 3, 3, 1792)   0           Block8_4_ScaleSum[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_4_Activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0a_1x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0a_1x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_5_Branch_1_Conv2d_0a_1x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0b_1x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0b_1x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_4_Activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_5_Branch_1_Conv2d_0b_1x3_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_5_Branch_0_Conv2d_1x1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0c_3x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_5_Branch_0_Conv2d_1x1_Batc\n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0c_3x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_5_Branch_0_Conv2d_1x1_Acti\n",
            "                                                                 Block8_5_Branch_1_Conv2d_0c_3x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_5_Concatenate[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_4_Activation[0][0]        \n",
            "                                                                 Block8_5_Conv2d_1x1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Activation (Activation (None, 3, 3, 1792)   0           Block8_5_ScaleSum[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_5_Activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0a_1x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0a_1x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_6_Branch_1_Conv2d_0a_1x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0b_1x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0b_1x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_5_Activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_6_Branch_1_Conv2d_0b_1x3_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_6_Branch_0_Conv2d_1x1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0c_3x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_6_Branch_0_Conv2d_1x1_Batc\n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0c_3x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_6_Branch_0_Conv2d_1x1_Acti\n",
            "                                                                 Block8_6_Branch_1_Conv2d_0c_3x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_6_Concatenate[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_5_Activation[0][0]        \n",
            "                                                                 Block8_6_Conv2d_1x1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "AvgPool (GlobalAveragePooling2D (None, 1792)         0           Block8_6_ScaleSum[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Dropout (Dropout)               (None, 1792)         0           AvgPool[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Bottleneck (Dense)              (None, 128)          229376      Dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Bottleneck_BatchNorm (BatchNorm (None, 128)          384         Bottleneck[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 22,808,144\n",
            "Trainable params: 22,779,312\n",
            "Non-trainable params: 28,832\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_5nBdHKOdLn",
        "colab_type": "code",
        "outputId": "f0e9e83e-181a-43b5-cf18-e3a001181509",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "test_num = sum([int(len(glob.glob('/content/drive/My Drive/Colab Notebooks/表情识别/{}_face/*.png'.format(i)))*random_ratio) for i in range(5)])\n",
        "train_num = sum([len(glob.glob('/content/drive/My Drive/Colab Notebooks/表情识别/{}_face/*.png'.format(i))) for i in range(5)])-test_num\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-661a1cae5a11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks/表情识别/{}_face/*.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrandom_ratio\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks/表情识别/{}_face/*.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtest_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-661a1cae5a11>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks/表情识别/{}_face/*.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrandom_ratio\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks/表情识别/{}_face/*.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtest_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'random_ratio' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpvN2f98PDnv",
        "colab_type": "code",
        "outputId": "697515a8-eda1-4e77-82c2-0fa0f0960099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "for layer in model.layers:\n",
        "    print(layer.trainable)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvt4jMPo7wcP",
        "colab_type": "code",
        "outputId": "eab810d6-cd31-4807-b60d-83b9f1574333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "\n",
        "\n",
        "steps_per_epoch = 1000\n",
        "batch_size = 128\n",
        "total_sum = 0\n",
        "epochs = 50\n",
        "random_ratio = 0.05\n",
        "\n",
        "filenames_train=['/content/drive/My Drive/Colab Notebooks/表情识别/face_train_{}.tfrecords'.format(i) for i in range(5)]\n",
        "filenames_test=['/content/drive/My Drive/Colab Notebooks/表情识别/face_test_{}.tfrecords'.format(i) for i in range(5)]\n",
        "\n",
        "# test_num = sum([int(len(glob.glob('./face/{}_face/*.png'.format(i)))*random_ratio) for i in range(5)])\n",
        "# train_num = sum([len(glob.glob('./face/{}_face/*.png'.format(i))) for i in range(5)])-test_num\n",
        "\n",
        "\n",
        "\n",
        "train_dataset=dataset(filenames_train,batch_size=batch_size,epochs=epochs)\n",
        "train_dataset=train_dataset.shuffle(buffer_size=(1000000))\n",
        "train_dataset=train_dataset.batch(batch_size).repeat(epochs*steps_per_epoch)\n",
        "train_dataset=train_dataset.prefetch(1)\n",
        "\n",
        "\n",
        "test_dataset=dataset(filenames_test,batch_size=batch_size,epochs=1)\n",
        "test_dataset=test_dataset.shuffle(buffer_size=(100000))\n",
        "test_dataset=test_dataset.batch(batch_size).repeat(20)\n",
        "test_dataset=test_dataset.prefetch(1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khK2AJKX8ulT",
        "colab_type": "code",
        "outputId": "7e2ef996-bf3f-47c7-b01a-629b43419f08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model.fit(train_dataset, steps_per_epoch=steps_per_epoch, epochs=epochs,validation_data=test_dataset,validation_steps=20, verbose=1)#)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 steps, validate on 20 steps\n",
            "Epoch 1/50\n",
            " 898/1000 [=========================>....] - ETA: 1:20 - loss: 0.7126 - acc: 0.7506"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVIONwgm1vFI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMhCHdhC1DW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf.add_to_collection('my_op',input_data)\n",
        "# tf.add_to_collection('my_op',output)\n",
        "# tf.add_to_collection('my_op',loss)\n",
        "\n",
        "# init = tf.global_variables_initializer()\n",
        "# saver = tf.train.Saver()\n",
        "# with tf.Session() as sess:\n",
        "#     sess.run([init])\n",
        "#     while epoch<epochs:\n",
        "#         data,label=sess.run([next_element_train[0],next_element_train[1]])\n",
        "#         total_sum+=batch_size\n",
        "#         _,loss_val = sess.run([train_op,loss],feed_dict={input_data:data,input_label:label})\n",
        "#          if total_sum%20==0:\n",
        "#             sys.stdout.write('epoch:{},index:{}\\\\{},loss:{:.4f}\\r'.format(epoch,total_sum%train_num,train_num,loss_val))\n",
        "#             sys.stdout.flush()\n",
        "#         if total_sum//train_num>epoch:\n",
        "#             epoch = total_sum//train_num\n",
        "#             loss_val = sess.run([loss],feed_dict={input_data:data,input_label:label})\n",
        "            \n",
        "#             next_element_test=dataset(filenames_test,batch_size=batch_size,epochs=1)\n",
        "#             total_test_sum = 0\n",
        "#             acc_test_lst = []\n",
        "#             while total_test_sum<test_num:\n",
        "#                 total_test_sum+=batch_size\n",
        "#                 test_data,test_label=sess.run([next_element_test[0],next_element_test[1]])\n",
        "#                 acc_test = sess.run([acc],feed_dict={input_data:test_data,input_label:test_label})\n",
        "#                 acc_test_lst.append(acc_test[0])\n",
        "#             acc_val = sum(acc_test_lst)/len(acc_test_lst)\n",
        "#             saver.save(sess, save_path=\"./model/my_model.ckpt\")\n",
        "#             print('epoch:{},train_loss:{:.4f},test_acc:{:.4f}'.format(epoch,loss_val[0],acc_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZU1zpUIZnhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}